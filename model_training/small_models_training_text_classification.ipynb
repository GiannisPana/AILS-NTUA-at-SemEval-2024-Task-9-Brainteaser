{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Install packages"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !pip install --force-reinstall numpy==1.22 # 1.23.4\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:54:46.762236Z","iopub.status.busy":"2024-02-17T23:54:46.761542Z","iopub.status.idle":"2024-02-17T23:55:54.163259Z","shell.execute_reply":"2024-02-17T23:55:54.162162Z","shell.execute_reply.started":"2024-02-17T23:54:46.762203Z"},"trusted":true},"outputs":[],"source":["!pip install datasets==2.14.6\n","!pip install transformers\n","!pip install evaluate\n","!pip install --no-cache-dir transformers sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:55:54.165428Z","iopub.status.busy":"2024-02-17T23:55:54.165120Z","iopub.status.idle":"2024-02-17T23:56:07.515575Z","shell.execute_reply":"2024-02-17T23:56:07.514647Z","shell.execute_reply.started":"2024-02-17T23:55:54.165400Z"},"trusted":true},"outputs":[],"source":["!pip install accelerate -U"]},{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, get_scheduler, TrainingArguments, Trainer, DataCollatorWithPadding, AutoModelForSequenceClassification\n","\n","# from string import Template\n","# from pathlib import Path\n","\n","import os\n","\n","import warnings\n","warnings.simplefilter(\"ignore\")\n","\n","from tqdm.notebook import tqdm\n","\n","import numpy as np\n","import pandas as pd\n","\n","from datasets import Dataset, DatasetDict\n","\n","from torch.utils.data import DataLoader\n","\n","\n","from IPython.display import Markdown, display"]},{"cell_type":"markdown","metadata":{},"source":["# Prepare training data"]},{"cell_type":"markdown","metadata":{},"source":["To access certain Language Model Models (LLMs) through the Hugging Face library, you may need to obtain an access token. You can acquire a token by signing up on the Hugging Face website and gaining permission to use the specific model you're interested in. \n","\n","The following cell demonstrates how to pass your access token in order to download the model and tokenizer. Put your access token in the `YOUR_HUGGING_FACE_TOKEN` variable."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from huggingface_hub import login\n","\n","login(token='YOUR_HUGGING_FACE_TOKEN')"]},{"cell_type":"markdown","metadata":{},"source":["Here we determine the model we are using and the sub-task we are solving (Sentence Puzzle or Word Puzzle)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["task = \"SP\"\n","model_name = \"FacebookAI/roberta-large\""]},{"cell_type":"markdown","metadata":{},"source":["### Importing into Colab\n","\n","Here we demonstrate how to import data into Colab. We have uploaded the data folder of the repository to a private Google Drive folder. Our folder is called `sem-dataset`."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:07.517234Z","iopub.status.busy":"2024-02-17T23:56:07.516926Z","iopub.status.idle":"2024-02-17T23:56:07.521347Z","shell.execute_reply":"2024-02-17T23:56:07.520516Z","shell.execute_reply.started":"2024-02-17T23:56:07.517205Z"},"trusted":true},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:07.524090Z","iopub.status.busy":"2024-02-17T23:56:07.523836Z","iopub.status.idle":"2024-02-17T23:56:07.534156Z","shell.execute_reply":"2024-02-17T23:56:07.533490Z","shell.execute_reply.started":"2024-02-17T23:56:07.524068Z"},"trusted":true},"outputs":[],"source":["# os.chdir('/content/drive/My Drive/sem-dataset')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:07.535553Z","iopub.status.busy":"2024-02-17T23:56:07.535231Z","iopub.status.idle":"2024-02-17T23:56:07.546301Z","shell.execute_reply":"2024-02-17T23:56:07.545608Z","shell.execute_reply.started":"2024-02-17T23:56:07.535521Z"},"trusted":true},"outputs":[],"source":["# train_data = np.load('./data/'+task+'-train.npy', allow_pickle=True)\n","\n","# test_data = np.load('./data/'+task+'_test_labeled.npy', allow_pickle=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Importing into Kaggle\n","\n","Here we demonstrate how to import data into Kaggle. We have uploaded the data folder of the repository to a private Kaggle dataset. Our dataset is called `sem-dataset`."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:07.547725Z","iopub.status.busy":"2024-02-17T23:56:07.547422Z","iopub.status.idle":"2024-02-17T23:56:07.566411Z","shell.execute_reply":"2024-02-17T23:56:07.565628Z","shell.execute_reply.started":"2024-02-17T23:56:07.547694Z"},"trusted":true},"outputs":[],"source":["for dirname, _, filenames in os.walk('/kaggle/input/sem-dataset'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"markdown","metadata":{},"source":["Here we import train and test data from the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:07.568032Z","iopub.status.busy":"2024-02-17T23:56:07.567439Z","iopub.status.idle":"2024-02-17T23:56:07.958763Z","shell.execute_reply":"2024-02-17T23:56:07.957971Z","shell.execute_reply.started":"2024-02-17T23:56:07.568001Z"},"trusted":true},"outputs":[],"source":["train_data = np.load('/kaggle/input/sem-dataset/'+task+'-train.npy', allow_pickle=True)\n","\n","test_data = np.load('/kaggle/input/sem-dataset/'+task+'_test_labeled.npy', allow_pickle=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Make directory for our output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:07.960165Z","iopub.status.busy":"2024-02-17T23:56:07.959792Z","iopub.status.idle":"2024-02-17T23:56:07.964296Z","shell.execute_reply":"2024-02-17T23:56:07.963233Z","shell.execute_reply.started":"2024-02-17T23:56:07.960139Z"},"trusted":true},"outputs":[],"source":["date_of_run = pd.to_datetime('today').strftime(\"%Y_%m_%d_%H_%M\")\n","\n","if '/' in model_name:\n","    # Split the model_name by \"/\"\n","    parts = model_name.split(\"/\")\n","    \n","    # Check if there are at least 4 parts\n","    if len(parts) >= 5:\n","        # Concatenate the 3rd and 4th parts with an underscore\n","        model_suffix = parts[3] + \"_\" + parts[5]\n","    else:\n","        # model_suffix = model_name\n","        model_suffix = model_name.replace('/', '_')\n","\n","\n","run_dir = \"./small_TxtCls_\" + task + \"_\" + model_suffix + \"_\" + date_of_run\n","print(run_dir)\n","\n","# Create the directory if it does not exist\n","if not os.path.exists(run_dir):\n","    os.makedirs(run_dir)\n","\n","os.chdir(run_dir)"]},{"cell_type":"markdown","metadata":{},"source":["# Basic preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["### Train dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:31.032886Z","iopub.status.busy":"2024-02-17T23:56:31.032319Z","iopub.status.idle":"2024-02-17T23:56:31.042474Z","shell.execute_reply":"2024-02-17T23:56:31.041422Z","shell.execute_reply.started":"2024-02-17T23:56:31.032858Z"},"trusted":true},"outputs":[],"source":["def convert_from_numpy_to_dataset_type (numpy_array, split):\n","    data_list = numpy_array.tolist()\n","    df = pd.DataFrame(data_list)\n","\n","    df = pd.DataFrame(data_list)\n","    df['id'] = df['id'].astype(str)      \n","    df['distractor1'] = df['distractor1'].astype(str)\n","    df['distractor2'] = df['distractor2'].astype(str)\n","    df['distractor(unsure)'] = df['distractor(unsure)'].astype(str)\n","    df['label'] = df['label'].astype(int)\n","\n","    dataset = Dataset.from_pandas(df,  split=split)\n","\n","    display(dataset[0])\n","\n","    display(dataset.features) # just to check the type of the features\n","\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:31.075531Z","iopub.status.busy":"2024-02-17T23:56:31.075179Z","iopub.status.idle":"2024-02-17T23:56:32.053010Z","shell.execute_reply":"2024-02-17T23:56:32.052111Z","shell.execute_reply.started":"2024-02-17T23:56:31.075500Z"},"trusted":true},"outputs":[],"source":["train_dataset = convert_from_numpy_to_dataset_type(train_data, \"train\")"]},{"cell_type":"markdown","metadata":{},"source":["### Test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:32.054989Z","iopub.status.busy":"2024-02-17T23:56:32.054374Z","iopub.status.idle":"2024-02-17T23:56:32.061218Z","shell.execute_reply":"2024-02-17T23:56:32.060350Z","shell.execute_reply.started":"2024-02-17T23:56:32.054955Z"},"trusted":true},"outputs":[],"source":["def convert_from_numpy_to_dataset_test_type (numpy_array):\n","    data_list = numpy_array.tolist()\n","    df = pd.DataFrame(data_list)\n","\n","    df = pd.DataFrame(data_list)\n","    df['id'] = df['id'].astype(str)      \n","    df['label'] = df['label'].astype(int)\n","\n","    dataset = Dataset.from_pandas(df)\n","\n","    display(dataset[0])\n","\n","    display(dataset.features) # just to check the type of the features\n","\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:32.063171Z","iopub.status.busy":"2024-02-17T23:56:32.062548Z","iopub.status.idle":"2024-02-17T23:56:32.082244Z","shell.execute_reply":"2024-02-17T23:56:32.081246Z","shell.execute_reply.started":"2024-02-17T23:56:32.063134Z"},"trusted":true},"outputs":[],"source":["test_dataset = convert_from_numpy_to_dataset_test_type(test_data)\n"]},{"cell_type":"markdown","metadata":{},"source":["Importing the tokenizer in order to tokenize the data.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_name)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Splitting the dataset"]},{"cell_type":"markdown","metadata":{},"source":["- We start by preprocessing the data, dividing it into three categories: Original, Semantic Reconstruction, and Context Reconstruction.\n","  \n","- Next, we split the training dataset into three subsets: train, validation, and test, for each of the three data categories. We perform this split before shuffling to ensure that the same identifiers (ids) are consistent across the training, validation, and test sets within each category.\n","\n","- After splitting, we concatenate and shuffle the data within each of the three categories (Original, Semantic, Context).\n","\n","- This approach is necessary because the dataset initially lacked a separate test set at the beginning of the competition.\n","\n","- Following the data preparation, we transform the multiple-choice task into a binary classification problem. For each unique identifier (id), we create four binary classification tasks based on the four multiple-choice options. Since the fourth option (\"None of the above\") is consistently irrelevant, we focus on the first three options to form our binary labels. We add a new column called `label`, assigning a value of 1 if the answer is correct and 0 otherwise. This allows us to train the model to predict correctness for each of the three binary classification tasks per unique identifier.\n","\n","- These preprocessing and transformation steps are applied not only to the training dataset but also to the test dataset used in the competition."]},{"cell_type":"markdown","metadata":{},"source":["#### Train dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:32.090527Z","iopub.status.busy":"2024-02-17T23:56:32.089938Z","iopub.status.idle":"2024-02-17T23:56:32.604484Z","shell.execute_reply":"2024-02-17T23:56:32.603729Z","shell.execute_reply.started":"2024-02-17T23:56:32.090496Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:32.612533Z","iopub.status.busy":"2024-02-17T23:56:32.612291Z","iopub.status.idle":"2024-02-17T23:56:32.789886Z","shell.execute_reply":"2024-02-17T23:56:32.789087Z","shell.execute_reply.started":"2024-02-17T23:56:32.612511Z"},"trusted":true},"outputs":[],"source":["ori_original_dataset = train_dataset.filter(lambda data: \"_SR\" not in data[\"id\"] and \"_CR\" not in data[\"id\"])\n","ori_scemantic_dataset = train_dataset.filter(lambda data: \"_SR\" in data[\"id\"]) # SR => Semantic Reconstruction\t\n","ori_context_dataset = train_dataset.filter(lambda data: \"_CR\" in data[\"id\"]) # CR => Context Reconstruction\n","\n","print(f\"Original dataset size: {len(ori_original_dataset)}\")\n","print(f\"Semantic dataset size: {len(ori_scemantic_dataset)}\")\n","print(f\"Context dataset size: {len(ori_context_dataset)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:32.791947Z","iopub.status.busy":"2024-02-17T23:56:32.791102Z","iopub.status.idle":"2024-02-17T23:56:32.797807Z","shell.execute_reply":"2024-02-17T23:56:32.797157Z","shell.execute_reply.started":"2024-02-17T23:56:32.791914Z"},"trusted":true},"outputs":[],"source":["def splitting_dataset(dataset, split_size):\n","    \n","    #split_size% test + validation\n","    train_testvalid = dataset.train_test_split(test_size=split_size, shuffle=False)\n","    \n","    # Split the rest test + valid in half test, half valid\n","    test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5, shuffle=False)\n","    \n","    # gather everyone if you want to have a single DatasetDict\n","    datasets = DatasetDict({\n","        \"train\": train_testvalid[\"train\"],\n","        \"test\": test_valid[\"test\"],\n","        \"valid\": test_valid[\"train\"]})\n","    \n","    return datasets\n"]},{"cell_type":"markdown","metadata":{},"source":["Here we are splitting the dataset into train, validation and test sets. **A good rule of thumb is to use 70% of the data for training, 15% for validation and 15% for testing.**\n","\n","<u>**WE DO NOT WANT TO SHUFFLE THE DATASET BEFORE SPLITTING IT TO KEEP THE ORDER OF THE SENTENCES!!!**</u>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:32.799179Z","iopub.status.busy":"2024-02-17T23:56:32.798878Z","iopub.status.idle":"2024-02-17T23:56:32.844302Z","shell.execute_reply":"2024-02-17T23:56:32.843466Z","shell.execute_reply.started":"2024-02-17T23:56:32.799150Z"},"trusted":true},"outputs":[],"source":["original_dataset = splitting_dataset(ori_original_dataset, 0.3)\n","scemantic_dataset = splitting_dataset(ori_scemantic_dataset, 0.3)\n","context_dataset = splitting_dataset(ori_context_dataset, 0.3)\n"]},{"cell_type":"markdown","metadata":{},"source":["Now we will make the only dataset that we will use for training and validation.\n","The testing will be done on several datasets."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:32.851177Z","iopub.status.busy":"2024-02-17T23:56:32.850891Z","iopub.status.idle":"2024-02-17T23:56:32.875357Z","shell.execute_reply":"2024-02-17T23:56:32.874473Z","shell.execute_reply.started":"2024-02-17T23:56:32.851149Z"},"trusted":true},"outputs":[],"source":["from datasets import concatenate_datasets\n","\n","assert original_dataset[\"train\"].features.type == scemantic_dataset[\"train\"].features.type\n","assert original_dataset[\"train\"].features.type == context_dataset[\"train\"].features.type\n","training_dataset = concatenate_datasets([original_dataset[\"train\"], scemantic_dataset[\"train\"], context_dataset[\"train\"]])\n","# print(f\"Training set size: {len(temp_training_dataset)}\")\n","# print(temp_training_dataset)\n","\n","assert original_dataset[\"valid\"].features.type == scemantic_dataset[\"valid\"].features.type\n","assert original_dataset[\"valid\"].features.type == context_dataset[\"valid\"].features.type\n","valid_dataset = concatenate_datasets([original_dataset[\"valid\"], scemantic_dataset[\"valid\"], context_dataset[\"valid\"]])\n","# print(f\"Validation set size: {len(valid_dataset)}\")\n","# print(valid_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:32.876693Z","iopub.status.busy":"2024-02-17T23:56:32.876443Z","iopub.status.idle":"2024-02-17T23:56:32.890942Z","shell.execute_reply":"2024-02-17T23:56:32.890116Z","shell.execute_reply.started":"2024-02-17T23:56:32.876672Z"},"trusted":true},"outputs":[],"source":["training_dataset = training_dataset.shuffle(seed=42)\n","valid_dataset = valid_dataset.shuffle(seed=42)\n","\n","\n","my_dataset = DatasetDict({\n","    \"train\": training_dataset,\n","    \"valid\": valid_dataset})\n","\n","print(my_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["#### Test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:32.919449Z","iopub.status.busy":"2024-02-17T23:56:32.919174Z","iopub.status.idle":"2024-02-17T23:56:32.988268Z","shell.execute_reply":"2024-02-17T23:56:32.987411Z","shell.execute_reply.started":"2024-02-17T23:56:32.919427Z"},"trusted":true},"outputs":[],"source":["test_original_dataset = test_dataset.filter(lambda data: \"_SR\" not in data[\"id\"] and \"_CR\" not in data[\"id\"])\n","test_scemantic_dataset = test_dataset.filter(lambda data: \"_SR\" in data[\"id\"]) # SR => Semantic Reconstruction\t\n","test_context_dataset = test_dataset.filter(lambda data: \"_CR\" in data[\"id\"]) # CR => Context Reconstruction\n","\n","print(f\"Original dataset size: {len(ori_original_dataset)}\")\n","print(f\"Semantic dataset size: {len(ori_scemantic_dataset)}\")\n","print(f\"Context dataset size: {len(ori_context_dataset)}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Tokenize after splitting"]},{"cell_type":"markdown","metadata":{},"source":["`create_binary_pairs` is a function that takes a row of our dataset and creates the binary pairs. It returns a list of the new rows."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:32.989493Z","iopub.status.busy":"2024-02-17T23:56:32.989263Z","iopub.status.idle":"2024-02-17T23:56:32.997444Z","shell.execute_reply":"2024-02-17T23:56:32.996481Z","shell.execute_reply.started":"2024-02-17T23:56:32.989472Z"},"trusted":true},"outputs":[],"source":["def create_binary_pairs(row):\n","    id = row['id']\n","    question = row['question']\n","    # correct_answer = row['answer']\n","    choices = row['choice_list']\n","    correct_answer = choices[row['label']]\n","    # choice_order = row['choice_order']\n","    \n","    binary_pairs = []\n","    \n","    # check if question contains '?' at the end\n","    question = question.strip()\n","    if question[-1] != '?':\n","        question = question + '?'\n","\n","    for i in range(len(choices)):\n","        choice = choices[i]\n","        \n","        # if choice contains \"None of the above\" skip it\n","        if \"none of above\" in choice.lower():\n","            continue\n","        \n","        # handle choice format\n","        formatted_choice = choice.strip()\n","        if formatted_choice[-1] != '.':\n","            formatted_choice = formatted_choice + '.'\n","            \n","        is_correct = (choice == correct_answer)\n","        label = 1 if is_correct else 0\n","\n","        # Concatenate the question and choice to create a new question\n","        new_question = f\"{question} {formatted_choice}\"\n","        \n","        # create new id to group these binary pairs together\n","        new_id = f\"{id}_{i}\"\n","        # new_id = f\"{i}\"\n","\n","        # Create a binary pair with the new question and label\n","        pair = {'id': new_id, 'question': new_question, 'label': label}\n","        binary_pairs.append(pair)\n","    \n","    # row['binary_pairs'] = binary_pairs\n","    \n","    # row['binary_pairs'] = binary_pairs\n","\n","    return binary_pairs\n"]},{"cell_type":"markdown","metadata":{},"source":["`create_binary_dataset` is a function that takes the dataset and creates the binary dataset. It returns a new dataset as a list."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:33.029542Z","iopub.status.busy":"2024-02-17T23:56:33.029285Z","iopub.status.idle":"2024-02-17T23:56:33.038431Z","shell.execute_reply":"2024-02-17T23:56:33.037742Z","shell.execute_reply.started":"2024-02-17T23:56:33.029521Z"},"trusted":true},"outputs":[],"source":["binary_dataset = []\n","def create_binary_dataset(example):\n","    binary_questions = create_binary_pairs(example)\n","    binary_dataset.extend(binary_questions)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:33.039572Z","iopub.status.busy":"2024-02-17T23:56:33.039346Z","iopub.status.idle":"2024-02-17T23:56:33.049003Z","shell.execute_reply":"2024-02-17T23:56:33.048172Z","shell.execute_reply.started":"2024-02-17T23:56:33.039551Z"},"trusted":true},"outputs":[],"source":["my_dataset[\"train\"].map(create_binary_dataset)\n","\n","print(\"Length of binary dataset: \", len(binary_dataset))\n","display(binary_dataset[:3])"]},{"cell_type":"markdown","metadata":{},"source":["Now we will create a binary pair dataset for the train, validation and test sets."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:33.050212Z","iopub.status.busy":"2024-02-17T23:56:33.049931Z","iopub.status.idle":"2024-02-17T23:56:33.291701Z","shell.execute_reply":"2024-02-17T23:56:33.290874Z","shell.execute_reply.started":"2024-02-17T23:56:33.050168Z"},"trusted":true},"outputs":[],"source":["list_of_datasets = [my_dataset[\"train\"], my_dataset[\"valid\"], original_dataset[\"test\"], scemantic_dataset[\"test\"], context_dataset[\"test\"], test_original_dataset, test_scemantic_dataset, test_context_dataset]\n","\n","all_data = []\n","\n","for i, dataset in enumerate(list_of_datasets):\n","    binary_dataset = []\n","    dataset.map(create_binary_dataset)\n","    print(\"Length of binary dataset: \", len(binary_dataset))\n","    \n","    all_data.append(binary_dataset)   \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:33.298589Z","iopub.status.busy":"2024-02-17T23:56:33.298339Z","iopub.status.idle":"2024-02-17T23:56:33.325622Z","shell.execute_reply":"2024-02-17T23:56:33.324817Z","shell.execute_reply.started":"2024-02-17T23:56:33.298568Z"},"trusted":true},"outputs":[],"source":["my_train_dataset = Dataset.from_list(all_data[0])\n","my_valid_dataset = Dataset.from_list(all_data[1])\n","\n","my_original_test_dataset = Dataset.from_list(all_data[2])\n","my_scemantic_test_dataset = Dataset.from_list(all_data[3])\n","my_context_test_dataset = Dataset.from_list(all_data[4])\n","\n","testset_original_test_dataset = Dataset.from_list(all_data[5])\n","testset_scemantic_test_dataset = Dataset.from_list(all_data[6])\n","testset_context_test_dataset = Dataset.from_list(all_data[7])\n","\n","\n","# Print the resulting dataset\n","# print(my_train_dataset)\n","# print(my_valid_dataset)\n","\n","# print(my_original_test_dataset)\n","# print(my_scemantic_test_dataset)\n","# print(my_context_test_dataset)\n","\n","# print(testset_original_test_dataset)\n","# print(testset_scemantic_test_dataset)\n","# print(testset_context_test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:33.326867Z","iopub.status.busy":"2024-02-17T23:56:33.326639Z","iopub.status.idle":"2024-02-17T23:56:33.330889Z","shell.execute_reply":"2024-02-17T23:56:33.330033Z","shell.execute_reply.started":"2024-02-17T23:56:33.326847Z"},"trusted":true},"outputs":[],"source":["my_dataset = DatasetDict({\n","    \"train\": my_train_dataset,\n","    \"valid\": my_valid_dataset})\n","\n","# print(my_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["Create the preprocessing function that will tokenize the data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:34.702136Z","iopub.status.busy":"2024-02-17T23:56:34.701798Z","iopub.status.idle":"2024-02-17T23:56:34.710044Z","shell.execute_reply":"2024-02-17T23:56:34.709131Z","shell.execute_reply.started":"2024-02-17T23:56:34.702103Z"},"trusted":true},"outputs":[],"source":["def preprocess_function(examples):\n","    return tokenizer(examples[\"question\"], truncation=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:34.711945Z","iopub.status.busy":"2024-02-17T23:56:34.711578Z","iopub.status.idle":"2024-02-17T23:56:34.733201Z","shell.execute_reply":"2024-02-17T23:56:34.732448Z","shell.execute_reply.started":"2024-02-17T23:56:34.711910Z"},"trusted":true},"outputs":[],"source":["my_dataset[\"train\"] = my_dataset[\"train\"].shuffle(seed=42) \n","my_dataset[\"valid\"] = my_dataset[\"valid\"].shuffle(seed=42) \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:34.734528Z","iopub.status.busy":"2024-02-17T23:56:34.734265Z","iopub.status.idle":"2024-02-17T23:56:34.741974Z","shell.execute_reply":"2024-02-17T23:56:34.741300Z","shell.execute_reply.started":"2024-02-17T23:56:34.734506Z"},"trusted":true},"outputs":[],"source":["list_of_datasets = [my_dataset[\"train\"], my_dataset[\"valid\"], my_original_test_dataset, my_scemantic_test_dataset, my_context_test_dataset, testset_original_test_dataset, testset_scemantic_test_dataset, testset_context_test_dataset]"]},{"cell_type":"markdown","metadata":{},"source":["Now we tokenize all the datasets."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:34.850648Z","iopub.status.busy":"2024-02-17T23:56:34.850385Z","iopub.status.idle":"2024-02-17T23:56:35.284329Z","shell.execute_reply":"2024-02-17T23:56:35.283517Z","shell.execute_reply.started":"2024-02-17T23:56:34.850626Z"},"trusted":true},"outputs":[],"source":["tokenized_datasets = []\n","\n","for i, dataset in enumerate(list_of_datasets):\n","    tokenized_datasets.append(dataset.map(preprocess_function, batched=True))\n","    # dataset = dataset.map(preprocess_function, batched=True)\n","    \n","    # display(tokenized_datasets[i].features)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:35.285781Z","iopub.status.busy":"2024-02-17T23:56:35.285510Z","iopub.status.idle":"2024-02-17T23:56:36.032288Z","shell.execute_reply":"2024-02-17T23:56:36.031564Z","shell.execute_reply.started":"2024-02-17T23:56:35.285757Z"},"trusted":true},"outputs":[],"source":["my_train_dataset = Dataset.from_list(tokenized_datasets[0])\n","my_valid_dataset = Dataset.from_list(tokenized_datasets[1])\n","\n","my_original_test_dataset = Dataset.from_list(tokenized_datasets[2])\n","my_scemantic_test_dataset = Dataset.from_list(tokenized_datasets[3])\n","my_context_test_dataset = Dataset.from_list(tokenized_datasets[4])\n","\n","\n","testset_original_test_dataset = Dataset.from_list(tokenized_datasets[5])\n","testset_scemantic_test_dataset = Dataset.from_list(tokenized_datasets[6])\n","testset_context_test_dataset = Dataset.from_list(tokenized_datasets[7])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:36.039507Z","iopub.status.busy":"2024-02-17T23:56:36.039160Z","iopub.status.idle":"2024-02-17T23:56:36.048409Z","shell.execute_reply":"2024-02-17T23:56:36.047584Z","shell.execute_reply.started":"2024-02-17T23:56:36.039476Z"},"trusted":true},"outputs":[],"source":["my_dataset = DatasetDict({\n","    \"train\": my_train_dataset,\n","    \"valid\": my_valid_dataset})\n","\n","# print(my_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["Here we are using `.map()` to apply the `preprocess` function to the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:36.086156Z","iopub.status.busy":"2024-02-17T23:56:36.085899Z","iopub.status.idle":"2024-02-17T23:56:36.178872Z","shell.execute_reply":"2024-02-17T23:56:36.178035Z","shell.execute_reply.started":"2024-02-17T23:56:36.086133Z"},"trusted":true},"outputs":[],"source":["tokenized_train = my_dataset[\"train\"].map(preprocess_function, batched=True)\n","print(f\"Training set size: {len(tokenized_train)}\")\n","# 396*3 = 1188"]},{"cell_type":"markdown","metadata":{},"source":["## Fine-tuning model"]},{"cell_type":"markdown","metadata":{},"source":["Data collator that will dynamically pad the inputs received, as well as the labels."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:36.184944Z","iopub.status.busy":"2024-02-17T23:56:36.184694Z","iopub.status.idle":"2024-02-17T23:56:36.205069Z","shell.execute_reply":"2024-02-17T23:56:36.204207Z","shell.execute_reply.started":"2024-02-17T23:56:36.184922Z"},"trusted":true},"outputs":[],"source":["data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate\n","\n","Including a metric during training is often helpful for evaluating your model’s performance. or this task, we load the accuracy metric."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:36.206886Z","iopub.status.busy":"2024-02-17T23:56:36.206290Z","iopub.status.idle":"2024-02-17T23:56:40.571474Z","shell.execute_reply":"2024-02-17T23:56:40.570602Z","shell.execute_reply.started":"2024-02-17T23:56:36.206855Z"},"trusted":true},"outputs":[],"source":["import evaluate\n","\n","accuracy = evaluate.load(\"accuracy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:40.573061Z","iopub.status.busy":"2024-02-17T23:56:40.572776Z","iopub.status.idle":"2024-02-17T23:56:40.578066Z","shell.execute_reply":"2024-02-17T23:56:40.577039Z","shell.execute_reply.started":"2024-02-17T23:56:40.573036Z"},"trusted":true},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return accuracy.compute(predictions=predictions, references=labels)"]},{"cell_type":"markdown","metadata":{},"source":["## Train"]},{"cell_type":"markdown","metadata":{},"source":["First we need to preprocess the data for the trainer.\n","\n","The `get_final_dataset` function modifies the input `dataset` by renaming the column \"label\" to \"labels\". \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:40.607773Z","iopub.status.busy":"2024-02-17T23:56:40.607525Z","iopub.status.idle":"2024-02-17T23:56:40.618181Z","shell.execute_reply":"2024-02-17T23:56:40.617499Z","shell.execute_reply.started":"2024-02-17T23:56:40.607750Z"},"trusted":true},"outputs":[],"source":["def get_final_dataset(dataset):\n","    tokenized_dataset = dataset.rename_column(\"label\", \"labels\")\n","    tokenized_dataset = tokenized_dataset.remove_columns(['id', 'question'])\n","    tokenized_dataset.set_format(\"torch\")\n","    return tokenized_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:40.619513Z","iopub.status.busy":"2024-02-17T23:56:40.619181Z","iopub.status.idle":"2024-02-17T23:56:40.644088Z","shell.execute_reply":"2024-02-17T23:56:40.643242Z","shell.execute_reply.started":"2024-02-17T23:56:40.619484Z"},"trusted":true},"outputs":[],"source":["tokenized_datasets = get_final_dataset(my_dataset)\n","\n","original_datasets = get_final_dataset(my_original_test_dataset)\n","scemantic_datasets = get_final_dataset(my_scemantic_test_dataset)\n","context_datasets = get_final_dataset(my_context_test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["Before we start training our model, we create a map of the expected ids to their labels with id2label and label2id:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:40.654993Z","iopub.status.busy":"2024-02-17T23:56:40.654689Z","iopub.status.idle":"2024-02-17T23:56:40.663675Z","shell.execute_reply":"2024-02-17T23:56:40.662988Z","shell.execute_reply.started":"2024-02-17T23:56:40.654964Z"},"trusted":true},"outputs":[],"source":["id2label = {0: \"FALSE\", 1: \"TRUE\"}\n","label2id = {\"FALSE\": 0, \"TRUE\": 1}"]},{"cell_type":"markdown","metadata":{},"source":["We disable Weights & Biases. You'll need to apply an API key when prompted if you use it for tracking the training metrics."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n"]},{"cell_type":"markdown","metadata":{},"source":["### Here we are loading the model we are using for the task."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:40.664998Z","iopub.status.busy":"2024-02-17T23:56:40.664630Z","iopub.status.idle":"2024-02-17T23:56:53.073659Z","shell.execute_reply":"2024-02-17T23:56:53.072629Z","shell.execute_reply.started":"2024-02-17T23:56:40.664969Z"},"trusted":true},"outputs":[],"source":["model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label=id2label, ignore_mismatched_sizes=True, label2id=label2id)"]},{"cell_type":"markdown","metadata":{},"source":["We check for the availability of a CUDA-enabled GPU and assign the appropriate device and then we move our model to that device for computation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:54.517639Z","iopub.status.busy":"2024-02-17T23:56:54.517375Z","iopub.status.idle":"2024-02-17T23:56:55.237144Z","shell.execute_reply":"2024-02-17T23:56:55.236127Z","shell.execute_reply.started":"2024-02-17T23:56:54.517615Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(device)\n","model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["Here we are passing basic arguments to the `Trainer` class.\n","- **`batch_size`**: This parameter determines the number of examples (data points) processed in each iteration (or batch) during training.\n","\n","- **`lr` (learning rate)**: This is the rate at which the model weights are updated during training.\n","\n","- **`num_epochs`**: Specifies the number of times the training dataset will be iterated over by the model during training.\n","\n","- **`num_training_steps`**: This calculates the total number of training steps that will be performed over the specified number of epochs.\n","\n","- **`batches_per_epoch`**: This represents the number of batches (or iterations) that will be processed in each epoch."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:55.239397Z","iopub.status.busy":"2024-02-17T23:56:55.238983Z","iopub.status.idle":"2024-02-17T23:56:55.245985Z","shell.execute_reply":"2024-02-17T23:56:55.244889Z","shell.execute_reply.started":"2024-02-17T23:56:55.239368Z"},"trusted":true},"outputs":[],"source":["batch_size = 4\n","\n","lr=3e-5 \n","\n","num_epochs = 3\n","# max_steps = 100\n","\n","num_training_steps = (len(my_dataset[\"train\"]) // batch_size) * num_epochs # num_epochs * len(train_dataloader)\n","batches_per_epoch = len(my_dataset[\"train\"]) // batch_size\n","# print(batches_per_epoch)"]},{"cell_type":"markdown","metadata":{},"source":["We are initializing optimizer and scheduler here."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T23:56:55.247852Z","iopub.status.busy":"2024-02-17T23:56:55.247525Z","iopub.status.idle":"2024-02-17T23:56:56.401322Z","shell.execute_reply":"2024-02-17T23:56:56.400242Z","shell.execute_reply.started":"2024-02-17T23:56:55.247826Z"},"trusted":true},"outputs":[],"source":["# Optimizer initialization\n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n","\n","# Learning rate scheduler initialization\n","lr_scheduler = get_scheduler(\n","    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Several arguments that we difine are the following:\n","\n","- `output_dir`: The directory where model checkpoints and outputs will be saved.\n","- `logging_steps`: Log metrics every specified number of training steps.\n","- `logging_strategy`: Specify whether logging is done by \"steps\" or \"epoch\".\n","- `save_strategy`: Strategy for saving model checkpoints, either by \"epoch\" or \"steps\".\n","- `save_steps`: Save a model checkpoint every specified number of steps.\n","- `save_total_limit`: Maximum number of checkpoints to keep.\n","- `evaluation_strategy`: Strategy for evaluating the model during training.\n","- `eval_steps`: Evaluate the model every specified number of training steps.\n","- `report_to`: Where to report evaluation results, set to \"none\" to disable reporting.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import accelerate\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./output\",\n","#     evaluation_strategy = \"epoch\", #To calculate metrics per epoch\n","    evaluation_strategy=\"steps\", # Evaluate the model every logging step\n","    eval_steps=20,\n","    \n","#     logging_strategy=\"epoch\", #Extra: to log training data stats for loss\n","    logging_steps=20,\n","    logging_strategy=\"steps\",\n","    \n","    learning_rate=lr,\n","    num_train_epochs=num_epochs,\n","    # max_steps=100,\n","\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    # warmup_steps=0,\n","    # weight_decay=0.01,\n","#     logging_dir=\"./logs\",\n","    report_to=None,  # Set report_to to None to disable integrations\n","    save_strategy=\"steps\",  # Set save_strategy to \"no\" to prevent saving model checkpoints\n","    save_steps=100,               # Save every 10 checkpoints\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"valid\"],\n","    optimizers=(optimizer, lr_scheduler),  # Pass both optimizer and scheduler\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Now we are ready to train our model!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Training loop using Trainer API\n","print('training model {}...'.format(model_name))\n","\n","train_result = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:29.566976Z","iopub.status.busy":"2024-02-18T00:01:29.566636Z","iopub.status.idle":"2024-02-18T00:01:29.572820Z","shell.execute_reply":"2024-02-18T00:01:29.571958Z","shell.execute_reply.started":"2024-02-18T00:01:29.566944Z"},"trusted":true},"outputs":[],"source":["metrics = train_result.metrics\n","trainer.save_metrics(\"train\", metrics)\n","trainer.save_state()"]},{"cell_type":"markdown","metadata":{},"source":["#### DataLoader\n","Create a DataLoader for our test datasets so we can iterate over batches of data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:29.612153Z","iopub.status.busy":"2024-02-18T00:01:29.611854Z","iopub.status.idle":"2024-02-18T00:01:29.622561Z","shell.execute_reply":"2024-02-18T00:01:29.621720Z","shell.execute_reply.started":"2024-02-18T00:01:29.612129Z"},"trusted":true},"outputs":[],"source":["\n","from torch.utils.data import DataLoader\n","\n","batch_size_dataloader = 2\n","\n","original_test_dataloader = DataLoader(original_datasets, batch_size=batch_size_dataloader, shuffle=False, collate_fn=DataCollatorWithPadding(tokenizer=tokenizer))\n","scemantic_test_dataloader = DataLoader(scemantic_datasets, batch_size=batch_size_dataloader, shuffle=False, collate_fn=DataCollatorWithPadding(tokenizer=tokenizer))\n","context_test_dataloader = DataLoader(context_datasets, batch_size=batch_size_dataloader, shuffle=False, collate_fn=DataCollatorWithPadding(tokenizer=tokenizer))\n"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluate\n","accumulate all the batches with add_batch and calculate the metric at the very end"]},{"cell_type":"markdown","metadata":{},"source":["##### Accuracy on each dataset (original, scemanic, context) by itself\n"]},{"cell_type":"markdown","metadata":{},"source":["In the following function we are calculating the accuracy of the model by each binary question, not for every triplet of questions."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:30.112623Z","iopub.status.busy":"2024-02-18T00:01:30.112303Z","iopub.status.idle":"2024-02-18T00:01:30.120841Z","shell.execute_reply":"2024-02-18T00:01:30.119923Z","shell.execute_reply.started":"2024-02-18T00:01:30.112599Z"},"trusted":true},"outputs":[],"source":["def compute_accuracy(dataloader, model):\n","    total_data = 0\n","    label_0_data = 0\n","\n","    metric = evaluate.load(\"accuracy\")\n","    model.eval()\n","    for batch in dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        with torch.no_grad():\n","            outputs = model(**batch)\n","\n","        logits = outputs.logits\n","        predictions = torch.argmax(logits, dim=-1)\n","        \n","        \n","        # Increment total_data counter\n","        total_data += batch[\"labels\"].size(0)\n","\n","        # Increment label_0_data counter\n","        label_0_data += (batch[\"labels\"] == 0).sum().item()\n","        \n","        # print(batch[\"labels\"])\n","        # print(predictions)\n","        # print()\n","        \n","        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n","\n","    temp_acc = metric.compute()\n","    temp_acc = round(temp_acc[\"accuracy\"], 3)\n","\n","    print(f\"test accuracy: {temp_acc}\")\n","    # print(f\"Total data points: {total_data}\")\n","    # print(f\"Data points with label 0: {label_0_data}\")\n","    \n","    # return original_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:30.122310Z","iopub.status.busy":"2024-02-18T00:01:30.122005Z","iopub.status.idle":"2024-02-18T00:01:33.116110Z","shell.execute_reply":"2024-02-18T00:01:33.114680Z","shell.execute_reply.started":"2024-02-18T00:01:30.122287Z"},"trusted":true},"outputs":[],"source":["compute_accuracy(original_test_dataloader, model)\n","print(\"##################################\")\n","compute_accuracy(scemantic_test_dataloader, model)\n","print(\"##################################\")\n","compute_accuracy(context_test_dataloader, model)\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Computing Initial Accuracy for Multiple-Choice Tasks\n","\n","Here, we are determining the accuracy of the original multiple-choice task by predicting binary classifications based on ids."]},{"cell_type":"markdown","metadata":{},"source":["We need to group the binary pairs created from the original dataset by the id of the same question.\n","\n","- The following function groups the binary pairs by the id of the same question. \n","- It returns a dictionary where the keys are the ids of the questions and the values are the binary pairs of the same question."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:33.189956Z","iopub.status.busy":"2024-02-18T00:01:33.189281Z","iopub.status.idle":"2024-02-18T00:01:33.198589Z","shell.execute_reply":"2024-02-18T00:01:33.197865Z","shell.execute_reply.started":"2024-02-18T00:01:33.189924Z"},"trusted":true},"outputs":[],"source":["def group_same_dataset(dataset):    \n","    # Initialize a dictionary to store the results\n","    grouped_pairs = {}\n","\n","    for id1 in dataset['id']:\n","        # print(id1)\n","        id1_list = id1.split('_')\n","        if len(id1_list) > 2:\n","            id1_list[0] = id1_list[0] + '_' + id1_list[1]\n","            id1_list[1] = id1_list[2]\n","            \n","        grouped_pairs[id1_list[0]] = [id1]\n","        \n","        for id2 in dataset['id']:\n","            id2_list = id2.split('_')\n","            if len(id2_list) > 2:\n","                id2_list[0] = id2_list[0] + '_' + id2_list[1]\n","                id2_list[1] = id2_list[2]\n","            if id1_list[0] in id2_list[0] and id1_list[1] != id2_list[1] and len(id1_list[0]) == len(id2_list[0]):\n","                grouped_pairs[id1_list[0]].append(id2)\n","        \n","    # print(grouped_pairs)\n","    \n","    for key in grouped_pairs:\n","        if len(grouped_pairs[key]) != 3:\n","            print(key)\n","            print(grouped_pairs[key])\n","            print()\n","    # assert len(grouped_pairs.values()) == 3\n","    return grouped_pairs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:33.199773Z","iopub.status.busy":"2024-02-18T00:01:33.199539Z","iopub.status.idle":"2024-02-18T00:01:33.239846Z","shell.execute_reply":"2024-02-18T00:01:33.239051Z","shell.execute_reply.started":"2024-02-18T00:01:33.199753Z"},"trusted":true},"outputs":[],"source":["grouped_pairs_original = group_same_dataset(my_original_test_dataset)\n","grouped_pairs_scemantic = group_same_dataset(my_scemantic_test_dataset)\n","grouped_pairs_context = group_same_dataset(my_context_test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["The function below will take row of dataset and model and return all the information needed to calculate the accuracy of the model on that row."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:33.241137Z","iopub.status.busy":"2024-02-18T00:01:33.240893Z","iopub.status.idle":"2024-02-18T00:01:33.246651Z","shell.execute_reply":"2024-02-18T00:01:33.245838Z","shell.execute_reply.started":"2024-02-18T00:01:33.241116Z"},"trusted":true},"outputs":[],"source":["def dataset_compute (row, model):\n","    \n","    prompt = row['question'][0].strip()\n","    # candidates = row['choice_list'][0]\n","    true_label_original = row['label'][0]\n","    # candidate_1, candidate_2, candidate_3, candidate_4 = candidates[0].strip(), candidates[1].strip(), candidates[2].strip(), candidates[3].strip()\n","    \n","    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(\"cuda\")\n","    \n","    # labels = torch.tensor(true_label_original).unsqueeze(0).to(\"cuda\")  # Batch size 1\n","    \n","    # Pass the input through the model to obtain predictions\n","    with torch.no_grad():\n","        logits = model(**inputs).logits\n","    \n","    # logits = outputs.logits\n","    predicted_class = logits.argmax().item()\n","    \n","    return prompt, true_label_original, predicted_class"]},{"cell_type":"markdown","metadata":{},"source":["The function below will take a dictionary of binary pairs and a model and return the accuracy of the model on that dictionary based on the correct prediction of all the triplets of questions."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:33.247948Z","iopub.status.busy":"2024-02-18T00:01:33.247706Z","iopub.status.idle":"2024-02-18T00:01:33.264723Z","shell.execute_reply":"2024-02-18T00:01:33.263870Z","shell.execute_reply.started":"2024-02-18T00:01:33.247927Z"},"trusted":true},"outputs":[],"source":["def compute_triplets_acc(dataset, group_pairs):\n","\n","    none_of_above = {}\n","\n","    total_correct_groups = 0.0\n","    total_groups = len(group_pairs)\n","    every_id = {}\n","    \n","    group_acc = {}\n","\n","    # we take question id and binary pairs id\n","    for group_id, group_ids_list in group_pairs.items():\n","        # print(group_id, group_ids_list)\n","        # Initialize a variable to check if all three ids in the group are correct\n","        # print(\"#\"*30)\n","#         print(group_id)\n","        all_correct = True\n","        \n","        a = {}\n","        correct_label = []\n","        \n","        # Check each id in the group\n","        for single_id in group_ids_list:\n","            # print(single_id)\n","            \n","            # we first filter the dataset to get the binary pair\n","            original_data = dataset.filter(lambda example: example['id'] == single_id)\n","            # print(original_data)\n","            \n","            # we then extract the prompt, true label and predicted label\n","            prompt, true_label_original, predicted_class = dataset_compute(original_data, model)\n","#             print(prompt, true_label_original, predicted_class)\n","#             print(true_label_original, predicted_class)\n","\n","            \n","            # # we store the prompt, true label and predicted label in a dictionary\n","            # a[single_id] = [prompt, true_label_original, predicted_class]\n","            \n","            correct_label.append(true_label_original)\n","            \n","            # Check if the prediction is correct\n","            if predicted_class != true_label_original:\n","                # we store the prompt, true label and predicted label in a dictionary\n","                a[single_id[-1]] = [prompt, true_label_original, predicted_class]\n","                all_correct = False\n","                # print(\"False\")\n","#                 print(prompt, true_label_original, predicted_class)\n","                # break  # No need to check further if one is incorrect\n","\n","        # print(len(correct_label))\n","        # print(\"#############################################\")\n","        \n","        if correct_label[0] == correct_label[1] == correct_label[2] == 0:\n","            # a.append(\"None of above\")\n","            none_of_above[group_id] = group_ids_list\n","            # print(group_id, group_ids_list)\n","        every_id[group_id] = a\n","        \n","        # If all three ids in the group are correct, increment the total correct groups\n","        if all_correct:\n","#             print(group_id)\n","            group_acc[group_id] = 1\n","            total_correct_groups += 1\n","#             print(total_correct_groups)\n","        else:\n","            group_acc[group_id] = 0\n","    \n","    # remove key-value pair if the value is empty\n","    every_id = {key: value for key, value in every_id.items() if value}\n","\n","    # Compute accuracy based on the total correct groups and total groups\n","    accuracy = total_correct_groups / total_groups\n","\n","    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n","    \n","    return every_id, none_of_above, accuracy, group_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:33.281690Z","iopub.status.busy":"2024-02-18T00:01:33.281470Z","iopub.status.idle":"2024-02-18T00:01:40.860838Z","shell.execute_reply":"2024-02-18T00:01:40.859970Z","shell.execute_reply.started":"2024-02-18T00:01:33.281670Z"},"trusted":true},"outputs":[],"source":["original_ids, original_none_of_above, original_acc, original_wrong_ids = compute_triplets_acc(my_original_test_dataset, grouped_pairs_original)\n","scemantic_ids, scemantic_none_of_above, scemantic_acc, scemantic_wrong_ids = compute_triplets_acc(my_scemantic_test_dataset, grouped_pairs_scemantic)\n","context_ids, context_none_of_above, context_acc, context_wrong_ids = compute_triplets_acc(my_context_test_dataset, grouped_pairs_context)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:40.879914Z","iopub.status.busy":"2024-02-18T00:01:40.879590Z","iopub.status.idle":"2024-02-18T00:01:40.892257Z","shell.execute_reply":"2024-02-18T00:01:40.891350Z","shell.execute_reply.started":"2024-02-18T00:01:40.879884Z"},"trusted":true},"outputs":[],"source":["print(\"Accuracy of original dataset:\")\n","print(round(original_acc, 3))\n","print(\"Accuracy of scemantic dataset:\")\n","print(round(scemantic_acc, 3))\n","print(\"Accuracy of context dataset:\")\n","print(round(context_acc, 3))\n"]},{"cell_type":"markdown","metadata":{},"source":["Here based on the `group` number we will calculate the accuracy of the model on that group."]},{"cell_type":"markdown","metadata":{},"source":["In the following function we are creating a detailed output of the predictions of the model on each group.\n","The function takes as input:\n","- a key of the dataset row that misspredictions were made\n","- the details of these prerpdictions\n","- the dataset name."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:40.902983Z","iopub.status.busy":"2024-02-18T00:01:40.902732Z","iopub.status.idle":"2024-02-18T00:01:40.916023Z","shell.execute_reply":"2024-02-18T00:01:40.915367Z","shell.execute_reply.started":"2024-02-18T00:01:40.902961Z"},"trusted":true},"outputs":[],"source":["def output_details(output_key, triplet_details, dataset_name, dataset):\n","    # Initialize the output template\n","    output_template = \"\"\n","\n","    # give title to the output\n","    output_template += \"  {} dataset:\\n\".format(dataset_name)\n","\n","    ############################ Initial Dataset ############################\n","    dataset_entry = dataset.filter(lambda example: example['id'] == output_key)[0]\n","    output_template += \"    Prompt: {}\\n\".format(dataset_entry['question'])\n","    output_template += \"    True Label: {} -> {}\\n\".format(dataset_entry['label'], dataset_entry['choice_list'][dataset_entry['label']].strip())\n","\n","    ############################ Triplets Dataset ############################\n","    infos = triplet_details[output_key]\n","\n","    for element in infos:\n","        true_label = infos[element][1]\n","\n","        element = int(element)\n","\n","        if dataset_entry['label'] == element and true_label == 0:\n","            output_template += \"    Predicted Label as correct: {} -> {}\\n\".format(element, dataset_entry['choice_list'][element].strip())\n","        elif dataset_entry['label'] == element and true_label == 1:\n","            output_template += \"    Predicted Label as wrong: {} -> {}\\n\".format(element, dataset_entry['choice_list'][element].strip())\n","        else:\n","            if true_label == 0:\n","                output_template += \"    Mispredicted Label as correct also: {} -> {}\\n\".format(element, dataset_entry['choice_list'][element].strip())\n","            else:\n","                output_template += \"    Mispredicted Label as wrong also: {} -> {}\\n\".format(element, dataset_entry['choice_list'][element].strip())\n","\n","    output_template += \"\\n\"\n","    return output_template\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:40.934427Z","iopub.status.busy":"2024-02-18T00:01:40.934138Z","iopub.status.idle":"2024-02-18T00:01:40.947253Z","shell.execute_reply":"2024-02-18T00:01:40.946355Z","shell.execute_reply.started":"2024-02-18T00:01:40.934405Z"},"trusted":true},"outputs":[],"source":["def group_accuracy(dataset, original_triplet_res, original_triplet_details,  scemantic_triplet_res, scemantic_triplet_details, context_triplet_res, context_triplet_details, num_groups=2):\n","    # correct_predictions = {}\n","    wrong_predictions = {}\n","    total_correct = 0\n","    model.eval()  # Set the model to evaluation mode\n","\n","    # Iterate over keys\n","    for i, key in enumerate(original_triplet_res.keys()):\n","        \n","        ############################ original dataset ############################\n","        is_original_correct = original_triplet_res[key]\n","        \n","        \n","        ############################ semantic dataset ############################\n","        is_semantic_correct = scemantic_triplet_res[key+'_SR']\n","        \n","        if num_groups == 3:\n","        ############################ context dataset ############################\n","            is_context_correct = context_triplet_res[key+'_CR']\n","\n","        # print(key)\n","        # if num_groups == 2:\n","        if is_original_correct and is_semantic_correct:\n","            total_correct += 1\n","            \n","        if not is_original_correct:\n","            if key not in wrong_predictions:\n","                wrong_predictions[key] = output_details(key, original_triplet_details, \"Original\", dataset)\n","            else:\n","                wrong_predictions[key] += output_details(key, original_triplet_details, \"Original\", dataset)\n","\n","        if not is_semantic_correct:\n","            if key not in wrong_predictions:\n","                wrong_predictions[key] = output_details(key+'_SR', scemantic_triplet_details, \"Semantic\", dataset)\n","            else:\n","                wrong_predictions[key] += output_details(key+'_SR', scemantic_triplet_details, \"Semantic\", dataset)\n","            \n","        if num_groups == 3: \n","            if not is_context_correct:\n","                if key not in wrong_predictions:\n","                    wrong_predictions[key] = output_details(key+'_CR', context_triplet_details, \"Context\", dataset)\n","                else:\n","                    wrong_predictions[key] += output_details(key+'_CR', context_triplet_details, \"Context\", dataset)\n","\n","        total_instances = i + 1\n","    accuracy = round(total_correct / total_instances, 3)\n","    if num_groups ==2:\n","        print(\"Accuracy Ori & Sem: {} -> {}/{}\".format(round(total_correct / total_instances, 3), total_correct, total_instances))\n","    else:\n","        print(\"Accuracy Ori & Sem & Con: {} -> {}/{}\".format(round(total_correct / total_instances, 3), total_correct, total_instances))\n","    \n","    return wrong_predictions, accuracy\n"]},{"cell_type":"markdown","metadata":{},"source":["### Ori & Sem Accuracy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:40.948471Z","iopub.status.busy":"2024-02-18T00:01:40.948215Z","iopub.status.idle":"2024-02-18T00:01:41.639358Z","shell.execute_reply":"2024-02-18T00:01:41.638537Z","shell.execute_reply.started":"2024-02-18T00:01:40.948449Z"},"trusted":true},"outputs":[],"source":["wrong_preds, ori_sem_accuracy = group_accuracy(train_dataset, original_wrong_ids, original_ids, scemantic_wrong_ids, scemantic_ids, context_wrong_ids, context_ids, num_groups=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:41.640843Z","iopub.status.busy":"2024-02-18T00:01:41.640537Z","iopub.status.idle":"2024-02-18T00:01:41.646385Z","shell.execute_reply":"2024-02-18T00:01:41.645537Z","shell.execute_reply.started":"2024-02-18T00:01:41.640818Z"},"trusted":true},"outputs":[],"source":["print(\"Accuracy is: \", ori_sem_accuracy)\n","# for key in wrong_preds:\n","#     print(key)\n","#     print(wrong_preds[key])\n","    \n","    \n","ori_sem_details = \"Accuracy: \" + str(ori_sem_accuracy) + '\\n\\n'\n","for key in wrong_preds:\n","    ori_sem_details += key + '\\n'\n","    ori_sem_details += wrong_preds[key] + '\\n'"]},{"cell_type":"markdown","metadata":{},"source":["### Ori & Sem & Con Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:41.647757Z","iopub.status.busy":"2024-02-18T00:01:41.647506Z","iopub.status.idle":"2024-02-18T00:01:42.839670Z","shell.execute_reply":"2024-02-18T00:01:42.838761Z","shell.execute_reply.started":"2024-02-18T00:01:41.647735Z"},"trusted":true},"outputs":[],"source":["wrong_preds, ori_sem_con_accuracy = group_accuracy(train_dataset, original_wrong_ids, original_ids, scemantic_wrong_ids, scemantic_ids, context_wrong_ids, context_ids, num_groups=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:42.841887Z","iopub.status.busy":"2024-02-18T00:01:42.841403Z","iopub.status.idle":"2024-02-18T00:01:42.848099Z","shell.execute_reply":"2024-02-18T00:01:42.847112Z","shell.execute_reply.started":"2024-02-18T00:01:42.841849Z"},"trusted":true},"outputs":[],"source":["print(\"Accuracy is: \", ori_sem_con_accuracy)\n","# for key in wrong_preds:\n","#     print(key)\n","#     print(wrong_preds[key])\n","    \n","    \n","ori_sem_con_details = \"Accuracy is: \" + str(ori_sem_con_accuracy) + '\\n\\n'\n","\n","for key in wrong_preds:\n","    ori_sem_con_details += key + '\\n'\n","    ori_sem_con_details += wrong_preds[key] + '\\n'"]},{"cell_type":"markdown","metadata":{},"source":["## For the competion Try the Trained Model!\n","\n","Here we handle the test set that is provided by the competition. We are following the same logic as above."]},{"cell_type":"markdown","metadata":{},"source":["### Prepare test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:42.849814Z","iopub.status.busy":"2024-02-18T00:01:42.849325Z","iopub.status.idle":"2024-02-18T00:01:42.868248Z","shell.execute_reply":"2024-02-18T00:01:42.867507Z","shell.execute_reply.started":"2024-02-18T00:01:42.849788Z"},"trusted":true},"outputs":[],"source":["testset_original_datasets = get_final_dataset(testset_original_test_dataset)\n","testset_scemantic_datasets = get_final_dataset(testset_scemantic_test_dataset)\n","testset_context_datasets = get_final_dataset(testset_context_test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:42.875616Z","iopub.status.busy":"2024-02-18T00:01:42.875386Z","iopub.status.idle":"2024-02-18T00:01:42.957470Z","shell.execute_reply":"2024-02-18T00:01:42.956597Z","shell.execute_reply.started":"2024-02-18T00:01:42.875596Z"},"trusted":true},"outputs":[],"source":["grouped_pairs_testset_original = group_same_dataset(testset_original_test_dataset)\n","grouped_pairs_testset_scemantic = group_same_dataset(testset_scemantic_test_dataset)\n","grouped_pairs_testset_context = group_same_dataset(testset_context_test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["### Predict with fine-tuned model\n","\n","##### Accuracy on each dataset (original, scemanic, context) by itself\n"]},{"cell_type":"markdown","metadata":{},"source":["The function below will take row of dataset and model and return all the information needed to calculate the accuracy of the model on that row."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:42.963877Z","iopub.status.busy":"2024-02-18T00:01:42.963606Z","iopub.status.idle":"2024-02-18T00:01:55.266580Z","shell.execute_reply":"2024-02-18T00:01:55.265680Z","shell.execute_reply.started":"2024-02-18T00:01:42.963855Z"},"trusted":true},"outputs":[],"source":["test_set_original_ids, test_set_original_none_of_above, test_set_original_acc, test_set_original_wrong_ids = compute_triplets_acc(testset_original_test_dataset, grouped_pairs_testset_original)\n","test_set_scemantic_ids, test_set_scemantic_none_of_above, test_set_scemantic_acc, test_set_scemantic_wrong_ids = compute_triplets_acc(testset_scemantic_test_dataset, grouped_pairs_testset_scemantic)\n","test_set_context_ids, test_set_context_none_of_above, test_set_context_acc, test_set_context_wrong_ids = compute_triplets_acc(testset_context_test_dataset, grouped_pairs_testset_context)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:55.286179Z","iopub.status.busy":"2024-02-18T00:01:55.285927Z","iopub.status.idle":"2024-02-18T00:01:55.298296Z","shell.execute_reply":"2024-02-18T00:01:55.297581Z","shell.execute_reply.started":"2024-02-18T00:01:55.286157Z"},"trusted":true},"outputs":[],"source":["print(\"Accuracy of original dataset:\")\n","print(round(test_set_original_acc, 3))\n","print(\"Accuracy of scemantic dataset:\")\n","print(round(test_set_scemantic_acc, 3))\n","print(\"Accuracy of context dataset:\")\n","print(round(test_set_context_acc, 3))\n"]},{"cell_type":"markdown","metadata":{},"source":["### Ori & Sem Accuracy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:55.312258Z","iopub.status.busy":"2024-02-18T00:01:55.311601Z","iopub.status.idle":"2024-02-18T00:01:56.150192Z","shell.execute_reply":"2024-02-18T00:01:56.149387Z","shell.execute_reply.started":"2024-02-18T00:01:55.312227Z"},"trusted":true},"outputs":[],"source":["test_set_wrong_preds, test_set_ori_sem_accuracy = group_accuracy(test_dataset, test_set_original_wrong_ids, test_set_original_ids, test_set_scemantic_wrong_ids, test_set_scemantic_ids, test_set_context_wrong_ids, test_set_context_ids, num_groups=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:56.151452Z","iopub.status.busy":"2024-02-18T00:01:56.151203Z","iopub.status.idle":"2024-02-18T00:01:56.156987Z","shell.execute_reply":"2024-02-18T00:01:56.156139Z","shell.execute_reply.started":"2024-02-18T00:01:56.151428Z"},"trusted":true},"outputs":[],"source":["print(\"Accuracy is: \", test_set_ori_sem_accuracy)\n","# for key in test_set_wrong_preds:\n","#     print(key)\n","#     print(test_set_wrong_preds[key])\n","    \n","\n","test_set_ori_sem_details = \"Accuracy is: \" + str(test_set_ori_sem_accuracy) + \"\\n\\n\"\n","\n","for key in test_set_wrong_preds:\n","    test_set_ori_sem_details += key + '\\n'\n","    test_set_ori_sem_details += test_set_wrong_preds[key] + '\\n'    "]},{"cell_type":"markdown","metadata":{},"source":["### Ori & Sem & Con Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:56.158538Z","iopub.status.busy":"2024-02-18T00:01:56.158214Z","iopub.status.idle":"2024-02-18T00:01:57.935653Z","shell.execute_reply":"2024-02-18T00:01:57.934738Z","shell.execute_reply.started":"2024-02-18T00:01:56.158507Z"},"trusted":true},"outputs":[],"source":["test_set_wrong_preds, test_set_ori_sem_con_accuracy = group_accuracy(test_dataset, test_set_original_wrong_ids, test_set_original_ids, test_set_scemantic_wrong_ids, test_set_scemantic_ids, test_set_context_wrong_ids, test_set_context_ids, num_groups=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:57.937048Z","iopub.status.busy":"2024-02-18T00:01:57.936768Z","iopub.status.idle":"2024-02-18T00:01:57.943890Z","shell.execute_reply":"2024-02-18T00:01:57.942777Z","shell.execute_reply.started":"2024-02-18T00:01:57.937022Z"},"trusted":true},"outputs":[],"source":["print(\"Accuracy is: \", test_set_ori_sem_con_accuracy)\n","# for key in test_set_wrong_preds:\n","#     print(key)\n","#     print(test_set_wrong_preds[key])\n","    \n","test_set_ori_sem_con_details = \"Accuracy is: \" + str(test_set_ori_sem_con_accuracy) + \"\\n\\n\"\n","\n","for key in test_set_wrong_preds:\n","    test_set_ori_sem_con_details += key + '\\n'\n","    test_set_ori_sem_con_details += test_set_wrong_preds[key] + '\\n'"]},{"cell_type":"markdown","metadata":{},"source":["Save information of mispredictions regarding group-based metric"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def save_to_text_file(content, filename):\n","    with open(filename, 'w') as file:\n","        file.write(content)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["save_to_text_file(ori_sem_details, './ori_sem_wrong.txt')\n","save_to_text_file(ori_sem_con_details, './ori_sem_con_wrong.txt')\n","\n","save_to_text_file(test_set_ori_sem_details, './test_set_ori_sem_wrong.txt')\n","save_to_text_file(test_set_ori_sem_con_details, './test_set_ori_sem_con_wrong.txt')"]},{"cell_type":"markdown","metadata":{},"source":["Gathering results to a json"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:57.967730Z","iopub.status.busy":"2024-02-18T00:01:57.967348Z","iopub.status.idle":"2024-02-18T00:01:58.012019Z","shell.execute_reply":"2024-02-18T00:01:58.011093Z","shell.execute_reply.started":"2024-02-18T00:01:57.967673Z"},"trusted":true},"outputs":[],"source":["df_res = pd.DataFrame(columns=['checkpoint', 'task',  'lr', 'batch_size', 'num_epochs', 'original_acc', 'scemantic_acc', 'context_acc', 'ori_sem_acc', 'ori_sem_con_acc', 'date_of_run'])\n","\n","# Create a dictionary for the new row\n","new_row_data = {\n","    'checkpoint': [model_name],\n","    'task': [task+\"__TxtCls\"],\n","    'lr': [lr],\n","    'batch_size': [batch_size],\n","    'num_epochs': [num_epochs],\n","    'original_acc': [original_acc],\n","    'semantic_acc': [scemantic_acc],\n","    'context_acc': [context_acc],\n","    'ori_sem_acc': [ori_sem_accuracy],\n","    'ori_sem_con_acc': [ori_sem_con_accuracy],\n","    'date_of_run': pd.to_datetime('today').strftime(\"%Y_%m_%d_%H:%M\")\n","}\n","\n","# Append the new row to the DataFrame\n","df_train = pd.DataFrame(new_row_data)\n","\n","# display(df_temp)\n","# df_temp.to_csv('./results.csv', index=False)\n","\n","new_row_test_set_data = {\n","    'checkpoint': [model_name],\n","    'task': [task+\"__TxtCls_test_set\"],\n","    'lr': [lr],\n","    'batch_size': [batch_size],\n","    'num_epochs': [num_epochs],\n","    'original_acc': [test_set_original_acc],\n","    'semantic_acc': [test_set_scemantic_acc],\n","    'context_acc': [test_set_context_acc],\n","    'ori_sem_acc': [test_set_ori_sem_accuracy],\n","    'ori_sem_con_acc': [test_set_ori_sem_con_accuracy],\n","    'date_of_run': pd.to_datetime('today').strftime(\"%Y_%m_%d_%H:%M\")\n","}\n","\n","# Append the new row to the DataFrame\n","df_test = pd.DataFrame(new_row_test_set_data)\n","\n","# display(df_temp)\n","# df_temp.to_csv('./results.csv', index=False)\n","\n","df_res = df_train._append(df_test, ignore_index=False)\n","display(df_res)\n","df_res.to_csv('./results.csv', index=False)\n","\n","# # df_res.to_csv('/kaggle/input/results/results.csv', index=True)\n","# df_res.to_csv('../results/results.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["##### Save model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T00:01:58.013440Z","iopub.status.busy":"2024-02-18T00:01:58.013132Z","iopub.status.idle":"2024-02-18T00:02:00.283713Z","shell.execute_reply":"2024-02-18T00:02:00.282919Z","shell.execute_reply.started":"2024-02-18T00:01:58.013414Z"},"trusted":true},"outputs":[],"source":["check = model_name[:model_name.find('/')]\n","\n","model.save_pretrained('./models/{}_{}_{}'.format(task, check, pd.to_datetime('today').strftime(\"%Y_%m_%d_%H_%M\")))"]},{"cell_type":"markdown","metadata":{},"source":["## Logic to export the results when running in Kaggle\n","\n","* The following logic produces a zip file of the results in order to download it. The zip file name can be change through the `NAME_OF_ZIP_FILE` variable."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(os.listdir(\"/kaggle/working/\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(os.listdir())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from zipfile import ZipFile\n","from IPython.display import FileLink\n","\n","NAME_OF_ZIP_FILE = run_dir\n","\n","# Directory to be zipped\n","directory_to_zip = '/kaggle/working/' + run_dir\n","\n","# Zip file name\n","zip_file_name = '{}.zip'.format(NAME_OF_ZIP_FILE)\n","\n","# Create a ZipFile object\n","with ZipFile(zip_file_name, 'w') as zip_obj:\n","    # Iterate over all files and directories in the specified directory\n","    for root, dirs, files in os.walk(directory_to_zip):\n","        for file in files:\n","            file_path = os.path.join(root, file)\n","            zip_obj.write(file_path, os.path.relpath(file_path, directory_to_zip))\n","\n","# Generate FileLink for the zipped file\n","FileLink(zip_file_name)\n"]},{"cell_type":"markdown","metadata":{},"source":["The following code is used to check the contents of the zip file."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Path to the ZIP file\n","zip_file_path = 'NAME_OF_ZIP_FILE.zip'  # Update with the path to your ZIP file\n","\n","# Open the ZIP file in read mode\n","with ZipFile(zip_file_path, 'r') as zip_file:\n","    # Print the list of elements (files and directories) inside the ZIP file\n","    print(\"Elements inside the ZIP file:\")\n","    for element in zip_file.namelist():\n","        print(element)\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4376497,"sourceId":7589968,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
